{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdVU8bUM2r0T"
      },
      "source": [
        "<figure>\n",
        "    <center> <img src=\"simple rag.png\"><center/>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Install Necessary Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxSkJt1bmEH",
        "outputId": "e74132d5-f4ad-4822-c5e1-895ec7517d88"
      },
      "outputs": [],
      "source": [
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU    # Embedding Model\n",
        "!pip install langchain-chroma -qU    # Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7B42w953C8M"
      },
      "source": [
        "## **Import Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDAx1z_Z3F0A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS5n-ZZS3Mdi"
      },
      "source": [
        "## **Initialize OpenAI LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Trj0ugL3Lkl"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize the ChatOpenAI Model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yRzMaVw3wiN"
      },
      "source": [
        "## **Initialize Embedding Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8UOt63o32S4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Initialize the OpenAIEmbeddings Model\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlslvdoW4H1o"
      },
      "source": [
        "## **Create Embeded Documents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN7Ec4924Fhk"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "# Define a list of documents with content and metadata\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"\"\"The T20 World Cup 2024 is in full swing, bringing excitement and drama to cricket fans worldwide. India's team, captained by Rohit Sharma, is preparing for a crucial match against Ireland, with standout player Jasprit Bumrah expected to play a pivotal role in their campaign. The tournament has already seen controversy, particularly concerning the pitch conditions at Nassau County International Cricket Stadium in New York, which came under fire after a low-scoring game between Sri Lanka and South Africa.\"\"\",\n",
        "        metadata={\"source\": \"cricket news\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"The world of football is buzzing with excitement as major tournaments and league matches continue to captivate fans globally. In the UEFA Champions League, the semi-final matchups have been set, with defending champions Real Madrid set to face Manchester City, while Bayern Munich will take on Paris Saint-Germain. Both ties promise thrilling encounters, featuring some of the best talents in world football.\"\"\",\n",
        "        metadata={\"source\": \"football news\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"As election season heats up, the latest developments reveal a highly competitive atmosphere across several key races. The presidential election has seen intense campaigning from all major candidates, with recent polls indicating a tight race. Incumbent President Jane Doe is seeking re-election on a platform of economic stability and healthcare reform, while her main rival, Senator John Smith, focuses on education and climate change initiatives.\"\"\",\n",
        "        metadata={\"source\": \"election news\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"The AI revolution continues to transform industries and reshape the global economy. Significant advancements in artificial intelligence have led to breakthroughs in healthcare, with AI-driven diagnostics improving patient outcomes and reducing costs. Autonomous systems are becoming increasingly prevalent in logistics and transportation, enhancing efficiency and safety.\"\"\",\n",
        "        metadata={\"source\": \"ai revolution news\"}\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtSC1uaMAr57"
      },
      "source": [
        "## **Create A Vector Store**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "rTwpXj40AsXt",
        "outputId": "92045c9d-e6ee-4163-f0f1-830d5c552d45"
      },
      "outputs": [],
      "source": [
        "# Create a vector store using the documents and embedding model\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embedding_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo-DIGzGBnF4"
      },
      "source": [
        "## **Perform Similarity Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_c6xJyMOAtcT",
        "outputId": "86d943c1-98b2-4958-f111-0d6af6802ec1"
      },
      "outputs": [],
      "source": [
        "results = vector_store.similarity_search(\"Test match\")\n",
        "\n",
        "for result in results:\n",
        "  print(\"-----------------\")\n",
        "  print(result.page_content)\n",
        "  print(result.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB3_jysXCH_g"
      },
      "outputs": [],
      "source": [
        "results = vector_store.similarity_search(\"Machine learning\")\n",
        "\n",
        "for result in results:\n",
        "  print(\"-----------------\")\n",
        "  print(result.page_content)\n",
        "  print(result.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzhaSvulCYJD"
      },
      "source": [
        "## **Embedded Query And Perform Similarity Search By Vector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Nn2vEaK5ClrY",
        "outputId": "02fe0614-d4d2-496a-beb8-a8593dbf8ee1"
      },
      "outputs": [],
      "source": [
        "# Embed a query using the embedding model\n",
        "query_embedding = embedding_model.embed_query(\"Machine learning\")\n",
        "\n",
        "# Check first ten values\n",
        "query_embedding[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "gIhHP9nsDAPC",
        "outputId": "a53aa18e-28b0-4b77-9701-37f8a87cbf61"
      },
      "outputs": [],
      "source": [
        "# Print the length of the query embedding\n",
        "len(query_embedding)  # this length same for all the queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8fF7o-l0DKYG",
        "outputId": "83cbd946-3536-4573-a3f6-ed786328ace9"
      },
      "outputs": [],
      "source": [
        "results = vector_store.similarity_search_by_vector(query_embedding, k=3)\n",
        "\n",
        "for result in results:\n",
        "  print(\"-----------------\")\n",
        "  print(result.page_content)\n",
        "  print(result.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEfxpMDRDlYC"
      },
      "source": [
        "## **Create Retriever**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQIG-MS9DkgV"
      },
      "outputs": [],
      "source": [
        "# create a retriever from the vector\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 1}\n",
        ")\n",
        "\n",
        "# Perform batch retrieval using the retriever\n",
        "batch_results = retriever.get_batch(\"machine learning\", \"test match\")\n",
        "\n",
        "for result in batch_results:\n",
        "  print(\"-----------------\")\n",
        "  for doc in result:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmzN9H_rKH4n"
      },
      "source": [
        "## **Create Prompt Template**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wai0MJg9KLDV"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Define the prompt template\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "# Create a chat prompt template from the message\n",
        "prompt = ChatPromptTemplate.from_massages([\n",
        "    (\"human\", message)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JydPJvq4L9wi"
      },
      "source": [
        "## **Chain Retriever And Prompt Template With LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhocfxoBMHGL"
      },
      "outputs": [],
      "source": [
        "chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZcdRFEiMiAs"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke(\"current state of 2024 t20 world cup\")  # this question for our own dataset questions in RAG architecture\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GamPFCCgM9LG"
      },
      "outputs": [],
      "source": [
        "response = chain.invoke(\"How are you\")  # Normal conversation messages\n",
        "print(response.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
